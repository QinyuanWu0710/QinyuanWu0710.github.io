---
layout: about
title: about
permalink: /

profile:
  align: right
  image: qinyuan.JPG
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>qwu [at] mpi-sws [dot] org</p>
    <p>Campus E1 5</p>
    <p>66125, Saarbruecken, Germany </p>

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

#Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

#Link to your social media connections, too. This theme is set up to use [Font Awesome icons](https://fontawesome.com/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them.

---

I am a third-year PhD student at the <a href="https://www.cis.mpg.de/">CS@Max Planck</a> and the <a href="https://www.mpi-sws.org/">Max Planck Institute for Software Systems (MPI-SWS)</a>, advised by <a href="https://people.mpi-sws.org/~gummadi/">Krishna Gummadi</a>. I am also fortunate to closely collaborate with and receive guidance from <a href="https://cs-people.bu.edu/evimaria/">Evimaria Terzi</a> (Boston University), <a href="https://mtoneva.com/">Mariya Toneva</a> (MPI-SWS), and <a href="https://informatik.rub.de/zafar/">Muhammad Bilal Zafar</a> (Ruhr University Bochum) (Odered by last name alphabet). Before I joined MPI-SWS, I got my bachelor degree in mathematics-physics from <a href="https://en.uestc.edu.cn/"> University of Electronic Science and Technology of China (UESTC)</a>.

I investigate how LLMs internalize and utilize knowledge, aiming to enhance their reliability and interpretability, delving into questions like memorization, knowledge estimation and knowledge learning of LLMs. 

Beyond this, I am enthusiastic about collaborating on:

1. *Privacy and security challenges in LLMs* – exploring ways to mitigate risks while maintaining model utility.
2. *The intersection of neuroscience and language models* – investigating how insights from the human brain can inform AI research and vice versa.
3. *Systems for serving LLMs* – including Parameter-Efficient Fine-Tuning (PEFT), quantization, and inference optimization methods like KV caching. While not an expert in LLM systems, I find it fascinating to explore how these optimizations influence model behavior.

<!-- Prior to joining MPI-SWS, I earned my bachelor's degree in mathematics-physics fundamental science from the <a href="https://www.yingcai.uestc.edu.cn//">Yingcai Honors College</a> at the <a href="https://en.uestc.edu.cn/">University of Electronic Science and Technology of China (UESTC)</a>. -->
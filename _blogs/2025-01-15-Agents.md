---
layout: blog
title: "Agents"
date: 2025-01-15
categories: agents
tags: [agents, llm, reading note]
---

# Overview of How to Build AI Agents

This reading note is a curated summary of papers and blog posts on AI agents. Many texts are directly quoted or adapted from the original sources. The primary goal is to consolidate and summarize key resources on AI agents for easy reference and study. Updates will be added as new developments arise.

*Note: Touch-ups by chatGPT.*

*Qinyuan Wu, last updated: 2025.01.15*

---

- [AI Agents](#ai-agents)
  - [What Are Agents?](#what-are-agents)
  - [Improving Reasoning and Planning Abilities](#improving-reasoning-and-planning-abilities)
    - [Task Decomposition](#task-decomposition)
    - [Self-Reflection](#self-reflection)
    - [Cognitive Architecture: Memory for Reasoning and Planning](#cognitive-architecture-memory-for-reasoning-and-planning)
  - [Using Tools](#using-tools)
    - [Data Stores](#data-stores)
    - [External APIs](#external-apis)
      - [Extensions](#extensions)
      - [Functions](#functions)
    - [Workflows](#workflows)
    - [Model Context Protocol (MCP)](#model-context-protocol-mcp)
  - [Environments](#environments)
  - [Enhancing Model Performance with Targeted Learning](#enhancing-model-performance-with-targeted-learning)
  - [Case Studies](#case-studies)
  - [Resources](#resources)

---

## What Are Agents?

What’s the difference between AI agents and AI models?

- **Models**: Trained systems that do not alter their parameters in the environment, such as pre-trained or fine-tuned LLMs. They serve as centralized decision-makers for agent processes.
- **Workflows**: Systems where LLMs and tools are orchestrated through predefined code paths. Tools bridge the gap between foundational models and external data/services.
- **Agents**: Systems where LLMs dynamically manage their processes and tool usage, maintaining control over how they accomplish tasks.

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/image-6.png" alt="alt text" style="width: 90%;" />
  <p><em>Overview of an AI agent, figure from <a href="https://www.anthropic.com/research/building-effective-agents">Building Effective Agents</a></em></p>
</div>

Agents achieve their goals using cognitive architectures that process information iteratively, make informed decisions, and refine actions based on previous outputs.

### Key Points:
1. Enabling the LLM’s **reasoning capabilities** to make good decisions:
   - *Task decomposition*: Frameworks like Chain-of-Thought (CoT) and Tree-of-Thought (ToT) are helpful.
   - *Self-reflection*: Allow agents to iteratively refine decisions and correct mistakes.
2. Ensuring the decision-making LLM **uses the right tools**.
3. Providing **feedback** from the environment and determining when to stop iterating.

## Improving Reasoning and Planning Abilities

### Task Decomposition

1. **[Chain of Thought (CoT)](https://arxiv.org/abs/2201.11903)**: A standard prompting technique instructing models to “think step by step,” breaking complex tasks into simpler steps. CoT enhances performance by utilizing more test-time computation and making the model’s reasoning process interpretable.

2. **[Tree of Thoughts (ToT)](https://arxiv.org/abs/2305.10601)**: Extends CoT by exploring multiple reasoning possibilities at each step. Problems are decomposed into thought steps, generating multiple thoughts per step, forming a tree structure. Searches can use BFS (breadth-first search) or DFS (depth-first search), with states evaluated by classifiers or majority vote.

### Self-Reflection

1. **[ReAct](https://arxiv.org/pdf/2210.03629)**: Combines reasoning and acting by expanding the action space to include task-specific actions and natural language reasoning traces. This enables interaction with the environment (e.g., using APIs) while documenting the reasoning process.

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/ReAct.png" alt="alt text" style="width: 80%;" />
  <p><em>Figure from <a href="https://arxiv.org/pdf/2210.03629">ReAct: Synergizing Reasoning and Acting in Language Models</a></em></p>
</div>

2. **[Reflexion](https://arxiv.org/abs/2303.11366)**: A framework equipping agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion uses a reinforcement learning setup where the reward model provides binary rewards, and actions follow the ReAct structure, incorporating task-specific actions and language-based reasoning.

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/image-8.png" alt="alt text" style="width: 80%;" />
  <p><em>Figure from <a href="https://arxiv.org/abs/2303.11366">Reflexion: Language Agents with Verbal Reinforcement Learning</a></em></p>
</div>

3. **[Chain of Hindsight](https://arxiv.org/abs/2302.02676)**
4. **[Algorithm Distillation](https://arxiv.org/abs/2210.14215)**

### Cognitive Architecture: Memory for Reasoning and Planning

Memory plays a crucial role in an agent’s reasoning process:

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/cognitive_arch_agents.png" alt="alt text" style="width: 40%;" />
  <p><em>Figure from <a href="https://arxiv.org/abs/2309.02427">Cognitive Architectures for Language Agents</a></em></p>
</div>

**Human Brain vs. Agent Memory**

Human cognitive architecture broadly includes:

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/image-9.png" alt="alt text" style="width: 80%;" />
  <p><em>Figure from <a href="https://lilianweng.github.io/posts/2023-06-23-agent/">Lil’s log: LLM Powered Autonomous Agents</a></em></p>
</div>

1. **Sensory Memory**: Learning embedding representations for raw inputs (e.g., text, images).
2. **Short-Term Memory**: In-context learning, limited by the finite context window of transformers.
3. **Long-Term Memory**: External vector stores for fast retrieval during query time.

Some researchers suggest aligning an agent’s cognitive architecture with the human brain’s.

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/CoALA.png" alt="alt text" style="width: 80%;" />
  <p><em>Figure from <a href="https://arxiv.org/abs/2309.02427">Cognitive Architectures for Language Agents</a></em></p>
</div>

## Using Tools

### Data Stores

Data stores convert incoming documents into vector database embeddings, allowing agents to extract necessary information. For example, Retrieval-Augmented Generation (RAG) uses vector embeddings to retrieve contextually relevant information.

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/data_stores.png" alt="alt text" style="width: 80%;" />
  <p><em>Figure from <a href="https://www.kaggle.com/whitepaper-agents">Google White Book: Agents</a></em></p>
</div>

### External APIs

1. **Tool Design**: Tools should be clearly defined and well-documented, with prompt engineering as detailed as the overall model prompts. Recommendations from [Building Effective Agents](https://www.anthropic.com/research/building-effective-agents):
   - Give the model enough tokens to “think” before committing to decisions.
   - Use natural formats familiar to the model.
   - Avoid excessive formatting overhead.

2. **Enhancing Model Performance**: Discussed further in the next section.

#### Extensions

Extensions bridge the gap between agents and APIs by teaching the agent:
1. How to use API endpoints with examples.
2. What arguments or parameters are required for successful API calls.

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/extensions.png" alt="alt text" style="width: 90%;" />
  <p><em>Figure from <a href="https://www.kaggle.com/whitepaper-agents">Google White Book: Agents</a></em></p>
</div>

#### Functions

Functions provide developers more control over API execution and data flow. For instance, a user requesting a ski trip suggestion might involve:

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/ski_model.png" alt="Ski Model" style="width: 80%;" />
  <p><em>Initial output from Ski Model</em></p>
</div>

The model’s output can be structured in JSON for easier parsing:

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/ski_json.png" alt="Ski JSON" style="width: 80%;" />
  <p><em>Ski Model Output in JSON Format</em></p>
</div>

This allows for better API usage:

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/ski_agent.png" alt="Ski Agent" style="width: 80%;" />
  <p><em>Ski Agent - External API Integration</em></p>
</div>

### Workflows

To integrate data stores and APIs in an agent system, developers build workflows using LLMs and tools. Examples include:

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/image-1.png" alt="Prompt chaining" style="width: 80%;" />
  <p><em>Prompt chaining with programmatic checks</em></p>
</div>

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/image-2.png" alt="Routing" style="width: 80%;" />
  <p><em>Routing</em></p>
</div>

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/image-3.png" alt="Parallelization" style="width: 80%;" />
  <p><em>Parallelization</em></p>
</div>

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/image-4.png" alt="Orchestrator-workers" style="width: 80%;" />
  <p><em>Orchestrator-workers</em></p>
</div>

<div style="text-align: center;">
  <img src="{{ site.baseurl }}/assets/images/image-5.png" alt="Evaluator-optimizer" style="width: 80%;" />
  <p><em>Evaluator-optimizer</em></p>
</div>

### Model Context Protocol (MCP)

The [Model Context Protocol (MCP)](https://www.anthropic.com/news/model-context-protocol) establishes secure connections to external systems like content repositories and business tools, ensuring models produce relevant, safe responses.

## Environments

Agents interact with their environments as "text games," receiving textual observations and producing textual actions.

1. **Physical Environments**: AI interacts with the physical world via perceptual inputs (e.g., vision, audio) converted into text and robotic planners executing commands.
2. **Dialogue Environments**: Agents engage in linguistic interactions, assisting with tasks or collaborating with other agents in simulations, debates, or problem-solving.
3. **Digital Environments**: AI operates in virtual platforms like APIs or websites, augmenting knowledge and computation in cost-effective, testable settings.

## Enhancing Model Performance with Targeted Learning

Strategies to improve model tool selection:
1. **In-Context Learning**: Example-based inference (e.g., ReAct framework).
2. **Retrieval-Based In-Context Learning**: Dynamically retrieves relevant information or tools from external memory.
3. **Fine-Tuning**: Pre-training on larger, specific datasets for enhanced performance.

## Case Studies

- **[Agent Laboratory: Using LLM Agents as Research Assistants](https://agentlaboratory.github.io/)**
- **[ResearchTown: Simulator of Human Research Community](https://arxiv.org/abs/2412.17767)**

---

## Resources

### Research Papers

- [Chain of Thought Prompting](https://arxiv.org/abs/2201.11903)
- [Tree of Thoughts](https://arxiv.org/abs/2305.10601)
- [ReAct](https://arxiv.org/pdf/2210.03629)
- [Reflexion](https://arxiv.org/abs/2303.11366)
- [Chain of Hindsight](https://arxiv.org/abs/2302.02676)
- [Algorithm Distillation](https://arxiv.org/abs/2210.14215)
- [Cognitive Architectures for Language Agents](https://arxiv.org/abs/2309.02427)

### Blog Posts and Reports

- [Lil’s Log: LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/)
- [Building Effective Agents](https://www.anthropic.com/research/building-effective-agents)
- [Agents](https://www.kaggle.com/whitepaper-agents)
- [Prompt Engineering Guide](https://www.promptingguide.ai/research/llm-agents)


### Frameworks

- [Langchain](https://python.langchain.com/v0.1/docs/modules/agents/)
- [Prompt engineering guide](https://www.promptingguide.ai/research/llm-agents)
- [Autogen](https://github.com/microsoft/autogen) 
- [AG2](https://ag2.ai/)
- [Promptflow](https://github.com/microsoft/promptflow)
- [LangGraph](https://langchain-ai.github.io/langgraph/)
- [Semantic Kernel](https://learn.microsoft.com/en-us/semantic-kernel/overview/)

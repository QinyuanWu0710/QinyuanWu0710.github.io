<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h1 id="overview-of-how-to-build-ai-agents">Overview of how to build AI Agents</h1> <hr> <p>This reading note is a curated summary of papers and blog posts on AI agents. Many texts are directly quoted or adapted from the original sources. The primary goal is to consolidate and summarize key resources on AI agents for easy reference and study. I’ll update if new things come.</p> <p>@Qinyuan Wu, last updation: 2025.01.15</p> <hr> <ul> <li> <a href="#ai-agents">AI Agents</a> <ul> <li><a href="#what-are-agents">What are agents?</a></li> <li> <a href="#how-to-improve-the-reasoningplanning-ability">How to improve the reasoning/planning ability</a> <ul> <li><a href="#task-decomposition">Task decomposition</a></li> <li><a href="#self-reflection">Self-reflection</a></li> <li><a href="#cognitive-archtecture-memories-provide-information-for-reasoningplanning">Cognitive archtecture: memories provide information for reasoning/planning</a></li> </ul> </li> <li> <a href="#how-to-use-tools">How to use tools</a> <ul> <li><a href="#data-stores">Data stores</a></li> <li> <a href="#external-apis">External APIs</a> <ul> <li><a href="#extensions">Extensions</a></li> <li><a href="#functions">Functions</a></li> </ul> </li> <li><a href="#workflows">Workflows</a></li> <li><a href="#others-model-context-protocol-mcp">Others: Model Context Protocol (MCP)</a></li> </ul> </li> <li><a href="#environments">Environments</a></li> <li><a href="#enhancing-model-performance-with-targeted-laerning">Enhancing model performance with targeted laerning</a></li> <li><a href="#case-study">Case study</a></li> <li><a href="#resources">Resources:</a></li> </ul> </li> </ul> <hr> <h2 id="what-are-agents">What are agents?</h2> <p>What’s the difference between AI agents and AI models?</p> <ul> <li> <strong>Models</strong>: Trained models that will not change the parameters in the environment, including pre-trained LLMs and fine-tuned LLMs. Models will be utilized as the centralized decision maker for agent processes.</li> <li> <strong>Workflows</strong>: Systems where LLMs and tools are orchestrated through predefined code paths. Tools bridge the gap between fundational models and the external data and services.</li> <li> <strong>Agent</strong>: Systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.</li> </ul> <div style="text-align: center;"> <img src="/assets/images/image-6.png" alt="alt text" style="width: 90%;"> <p><em> Overview of an AI agent, figure from <a href="https://www.anthropic.com/research/building-effective-agents" rel="external nofollow noopener" target="_blank">Building effective agents</a></em></p> </div> <p>Agents can use cognitive architectures to reach their end goals by iteratively processing information, making informed decisions, and refining next actions based on previous outputs.</p> <ol> <li> <p>The first key point in the loop is <strong>how to enable the LLM’s reasoning capabilities</strong> to make a good decision. a. <em>Task decomposition</em>: some prompt engineering framework can help here like chain-of-thought (CoT) and tree-of-thought (ToT). b. <em>Self-reflection</em>: allow autonomous sgents to improve iteratively by refining past action decisions and correcting previous mistakes.</p> </li> <li> <p>The second key point in the loop is how to make sure the decision maker LLM <strong>uses right tools</strong>.</p> </li> <li> <p>The third key point in the loop is how to give the <strong>good feedback</strong> from the environment and how to decide to stop from the loop.</p> </li> </ol> <h2 id="how-to-improve-the-reasoningplanning-ability">How to improve the reasoning/planning ability</h2> <h3 id="task-decomposition">Task decomposition</h3> <ol> <li> <a href="https://arxiv.org/abs/2201.11903" rel="external nofollow noopener" target="_blank">Chain of thought</a> has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.</li> <li> <a href="https://arxiv.org/abs/2305.10601" rel="external nofollow noopener" target="_blank">Tree of Thoughts</a> extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.</li> </ol> <h3 id="self-reflection">Self-reflection</h3> <ol> <li> <a href="https://arxiv.org/pdf/2210.03629" rel="external nofollow noopener" target="_blank">ReAct</a>: integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.</li> </ol> <div style="text-align: center;"> &lt;img <img src="/assets/images/ReAct.png" alt="alt text" style="width: 80%;"> <p><em>The figure is from <a href="https://arxiv.org/pdf/2210.03629" rel="external nofollow noopener" target="_blank">ReAct: Synergizing Reasoning and Acting in Language Models</a></em></p> </div> <ol> <li> <a href="https://arxiv.org/abs/2303.11366" rel="external nofollow noopener" target="_blank">Reflection</a> is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps.</li> </ol> <div style="text-align: center;"> <img src="/assets/images/image-8.png" alt="alt text" style="width: 80%;"> <p><em>The figure is from <a href="https://arxiv.org/abs/2303.11366" rel="external nofollow noopener" target="_blank">Reflexion: Language Agents with Verbal Reinforcement Learning</a></em></p> </div> <p>The heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped.</p> <ol> <li><a href="https://arxiv.org/abs/2302.02676" rel="external nofollow noopener" target="_blank">Chain of Hindsight</a></li> <li><a href="https://arxiv.org/abs/2210.14215" rel="external nofollow noopener" target="_blank">Algorithm Distillation</a></li> </ol> <h3 id="cognitive-archtecture-memories-provide-information-for-reasoningplanning">Cognitive archtecture: memories provide information for reasoning/planning</h3> <p>How the memory plays its role for the agent’s internal reasoning:</p> <div style="text-align: center;"> <img src="/assets/images/cognitive_arch_agents.png" alt="alt text" style="width: 40%;"> <p><em>The figure is from <a href="https://arxiv.org/abs/2309.02427" rel="external nofollow noopener" target="_blank">Cognitive Architectures for Language Agents</a></em></p> </div> <p><strong>Memory for agents VS memory in human brain</strong></p> <p>The human brain encompasses various types of memory, with its cognitive architecture broadly including the following components:</p> <div style="text-align: center;"> <img src="/assets/images/image-9.png" alt="alt text" style="width: 80%;"> <p><em>The figure is from <a href="https://lilianweng.github.io/posts/2023-06-23-agent/" rel="external nofollow noopener" target="_blank">Lil's log: LLM Powered Autonomous Agents</a></em></p> </div> <ol> <li> <strong>Sensory memory</strong> as <strong>learning embedding representations</strong> for raw inputs, including text, image or other modalities;</li> <li> <strong>Short-term memory</strong> as <strong>in-context learning</strong>. It is short and finite, as it is restricted by the finite context window length of Transformer. The reasoning is limited by the context window.</li> <li> <strong>Long-term memory</strong> as the <strong>external vector store</strong> that the agent can attend to at query time, accessible via fast retrieval.</li> </ol> <p>Some works proposed we should have a cognitive architecture for an agent should align with human brain’s cognitive architecture.</p> <div style="text-align: center;"> <img src="/assets/images/CoALA.png" alt="alt text" style="width: 80%;"> <p><em>The figure is from <a href="https://arxiv.org/abs/2309.02427" rel="external nofollow noopener" target="_blank">Cognitive Architectures for Language Agents</a></em></p> </div> <h2 id="how-to-use-tools">How to use tools</h2> <h3 id="data-stores">Data stores</h3> <p>Data stores convert the incoming document into a set of vector database embeddings that the agent can use to extract information it needs to supplement its next action or response to the user. The key point is to store data in the form of vector embeddings. One of the most common application is the RAG based applications. For different kinds of data, the agent can have different kinds of data store.</p> <div style="text-align: center;"> <img src="/assets/images/data_stores.png" alt="alt text" style="width: 80%;"> <p><em>The figure is from <a href="https://www.kaggle.com/whitepaper-agents" rel="external nofollow noopener" target="_blank">Google White Book: Agents</a></em></p> </div> <h3 id="external-apis">External APIs</h3> <ol> <li> <p>The designer should carefully design toolsets and their documentation clearly and thoughtfully. Tool definitions and specifications should be given just as much prompt engineering attention as your overall prompts.</p> <p>Interesting prompt engineering suggestions from <a href="https://www.anthropic.com/research/building-effective-agents" rel="external nofollow noopener" target="_blank">Building effective agents</a>:</p> <blockquote> <ol> <li>Give the model enough tokens to “think” before it writes itself into a corner.</li> <li>Keep the format close to what the model has seen naturally occurring in text on the internet.</li> <li>Make sure there’s no formatting “overhead” such as having to keep an accurate count of thousands of lines of code, or string-escaping any code it writes.</li> </ol> </blockquote> </li> <li> <p>Enhancing model performance with targeted learning – we will talk about it in the next section.</p> </li> </ol> <h4 id="extensions">Extensions</h4> <p>An extension bridges the gap between an agent and an API by:</p> <ol> <li>Teaching the agent how to use the API endpoint using examples.</li> <li>Teaching the agent what arguments or parameters are needed to successfully call the API endpoint.</li> </ol> <div style="text-align: center;"> <img src="/_blogs/asserts/images/extensions.png" alt="alt text" style="width: 90%;"> <p><em>The figure is from <a href="https://www.kaggle.com/whitepaper-agents" rel="external nofollow noopener" target="_blank">Google White Book: Agents</a></em></p> </div> <h4 id="functions">Functions</h4> <p>The agent developer might not want the LLM to manage the API execution (extensions) because of security or additional data transformation logic needs to be applied to the API response. So we want the model can be used to invoke <strong>functions</strong> in order to handle complex, client-side execution flows for the end user.</p> <p>A typical conversation when the user ask for a ski trip suggestion:</p> <div style="text-align: center;"> <img src="/_blogs/asserts/images/ski_model.png" alt="Ski Model" style="width: 80%;"> <p><em> Ski Model - Initial Output</em></p> </div> <p>While the above output contains the data that we need (city names), the format isn’t ideal for parsing. With Function Calling, we can teach a model to format this output in a structured style (like JSON) that’s more convenient for another system to parse.</p> <div style="text-align: center;"> <img src="/asserts/images/ski_json.png" alt="Ski JSON" style="width: 80%;"> <p><em> Ski Model Output in JSON Format</em></p> </div> <p>This JSON format output can help the model to use the external API better:</p> <div style="text-align: center;"> <img src="/asserts/images/ski_agent.png" alt="Ski Agent" style="width: 80%;"> <p><em> Ski Agent - External API Integration</em></p> </div> <p>One key thing to remember about functions is that they are meant to offer the developer much more control over not only the execution of API calls, but also the entire flow of data in the application as a whole.</p> <h3 id="workflows">Workflows</h3> <p>Now we know how to build external data stores and how to use external APIs, the key part to use them in an Agent system is to build your own workflows used LLMs and those tools. Here are some abstractions of workflows.</p> <p>All those figures in workflows are coming from <a href="https://www.anthropic.com/research/building-effective-agents" rel="external nofollow noopener" target="_blank">Abtriouc: Building effective agents</a></p> <div style="text-align: center;"> <img src="/asserts/images/image-1.png" alt="Ski Agent" style="width: 80%;"> <p><em>Prompt chaining, the gate can me programmatic checks.</em></p> </div> <div style="text-align: center;"> <img src="/asserts/images/image-2.png" alt="Ski Agent" style="width: 80%;"> <p><em>Routing</em></p> </div> <div style="text-align: center;"> <img src="/asserts/images/image-3.png" alt="Parallelization" style="width: 80%;"> <p><em>Parallelization</em></p> </div> <div style="text-align: center;"> <img src="/asserts/images/image-4.png" alt="Orchestrator-workers" style="width: 80%;"> <p><em>Orchestrator-workers</em></p> </div> <div style="text-align: center;"> <img src="/asserts/images/image-5.png" alt="Evaluator-optimizer" style="width: 80%;"> <p><em>Evaluator-optimizer</em></p> </div> <h3 id="others-model-context-protocol-mcp">Others: <a href="https://www.anthropic.com/news/model-context-protocol" rel="external nofollow noopener" target="_blank">Model Context Protocol (MCP)</a><a href="https://www.anthropic.com/news/model-context-protocol" rel="external nofollow noopener" target="_blank"></a> </h3> <p><strong>Make sure safe connection with external sources.</strong> A new standard for connecting AI assistants to the systems where data lives, including content repositories, business tools, and development environments. Its aim is to help frontier models produce better, more relevant responses.</p> <h2 id="environments">Environments</h2> <p>This effectively simplifies the agent’s interaction with the outside world as a “text game” with textual observations and actions.</p> <h2 id="enhancing-model-performance-with-targeted-laerning">Enhancing model performance with targeted laerning</h2> <p>To help the model gain access to this type of specific knowledge about which tools it should select, here are some strategies:</p> <ol> <li>In-context learning (example: ReAct framework): provide few-shot examples at inference.</li> <li>Retrieval-based in-context learning: dynamically populates the model prompt with the most relevant information, tools, and associated examples by retrieving them from external memory.</li> <li>Fine-tuning based learning: training a model using a larger dataset of specific examples prior to inference.</li> </ol> <h2 id="case-study">Case study</h2> <p><a href="https://agentlaboratory.github.io/" rel="external nofollow noopener" target="_blank">Agent laboratory: using LLM agents as research assistants</a></p> <p><a href="https://arxiv.org/abs/2412.17767" rel="external nofollow noopener" target="_blank">ResearchTown: Simulator of Human Research Community</a></p> <hr> <h2 id="resources">Resources:</h2> <p><em>The resources list is generated by ChatGPT.</em> :)</p> <ul> <li>Research Papers <ul> <li><a href="https://arxiv.org/abs/2201.11903" rel="external nofollow noopener" target="_blank">Chain of Thought Prompting</a></li> <li><a href="https://arxiv.org/abs/2305.10601" rel="external nofollow noopener" target="_blank">Tree of Thoughts</a></li> <li><a href="https://arxiv.org/pdf/2210.03629" rel="external nofollow noopener" target="_blank">ReAct</a></li> <li><a href="https://arxiv.org/abs/2303.11366" rel="external nofollow noopener" target="_blank">Reflexion</a></li> <li><a href="https://arxiv.org/abs/2302.02676" rel="external nofollow noopener" target="_blank">Chain of Hindsight</a></li> <li><a href="https://arxiv.org/abs/2210.14215" rel="external nofollow noopener" target="_blank">Algorithm Distillation</a></li> <li><a href="https://arxiv.org/abs/2309.02427" rel="external nofollow noopener" target="_blank">Cognitive Architectures for Language Agents</a></li> </ul> </li> <li>Blog Posts and Reports <ul> <li><a href="https://lilianweng.github.io/posts/2023-06-23-agent/" rel="external nofollow noopener" target="_blank">Lil’s Log: LLM Powered Autonomous Agents</a></li> <li><a href="https://www.anthropic.com/research/building-effective-agents" rel="external nofollow noopener" target="_blank">Building Effective Agents</a></li> <li><a href="Agents">Agents</a></li> <li><a href="https://www.promptingguide.ai/research/llm-agents" rel="external nofollow noopener" target="_blank">Prompt Engineering Guide</a></li> </ul> </li> </ul> </body></html>
<!DOCTYPE html><html><head>
      <title>Agents</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:////Users/qinyuan/.vscode/extensions/shd101wyy.markdown-preview-enhanced-0.8.15/crossnote/dependencies/katex/katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h1 id="ai-agents">AI Agents </h1>
<hr>
<p>This reading note is a curated summary of papers and blog posts on AI agents. Many texts are directly quoted or adapted from the original sources. The primary goal is to consolidate and summarize key resources on AI agents for easy reference and study. I'll update if new things come.</p>
<p>@Qinyuan Wu, last updation: 2025.01.15</p>
<hr>
<ul>
<li><a href="#ai-agents">AI Agents</a>
<ul>
<li><a href="#what-are-agents">What are agents?</a></li>
<li><a href="#how-to-improve-the-reasoningplanning-ability">How to improve the reasoning/planning ability</a>
<ul>
<li><a href="#task-decomposition">Task decomposition</a></li>
<li><a href="#self-reflection">Self-reflection</a></li>
<li><a href="#cognitive-archtecture-memories-provide-information-for-reasoningplanning">Cognitive archtecture: memories provide information for reasoning/planning</a></li>
</ul>
</li>
<li><a href="#how-to-use-tools">How to use tools</a>
<ul>
<li><a href="#data-stores">Data stores</a></li>
<li><a href="#external-apis">External APIs</a>
<ul>
<li><a href="#extensions">Extensions</a></li>
<li><a href="#functions">Functions</a></li>
</ul>
</li>
<li><a href="#workflows">Workflows</a></li>
<li><a href="#others-model-context-protocol-mcp">Others: Model Context Protocol (MCP)</a></li>
</ul>
</li>
<li><a href="#environments">Environments</a></li>
<li><a href="#enhancing-model-performance-with-targeted-laerning">Enhancing model performance with targeted laerning</a></li>
<li><a href="#case-study">Case study</a></li>
<li><a href="#resources">Resources:</a></li>
</ul>
</li>
</ul>
<hr>
<h2 id="what-are-agents">What are agents? </h2>
<p>What's the difference between AI agents and AI models?</p>
<ul>
<li><strong>Models</strong>: Trained models that will not change the parameters in the environment, including pre-trained LLMs and fine-tuned LLMs. Models will be utilized as the centralized decision maker for agent processes.</li>
<li><strong>Workflows</strong>: Systems where LLMs and tools are orchestrated through predefined code paths. Tools bridge the gap between fundational models and the external data and services.</li>
<li><strong>Agent</strong>: Systems where LLMs dynamically direct their own processes and tool usage, maintaining control over how they accomplish tasks.</li>
</ul>
<div style="text-align: center;">
  <img src="image-6.png" alt="alt text" style="width: 90%;">
  <p><em> Overview of an AI agent, figure from <a href="https://www.anthropic.com/research/building-effective-agents">Building effective agents</a></em></p>
</div>
<p>Agents can use cognitive architectures to reach their end goals by iteratively processing information, making informed decisions, and refining next actions<br>
based on previous outputs.</p>
<ol>
<li>
<p>The first key point in the loop is <strong>how to enable the LLM's reasoning capabilities</strong> to make a good decision.<br>
a. <em>Task decomposition</em>: some prompt engineering framework can help here like chain-of-thought (CoT) and tree-of-thought (ToT).<br>
b. <em>Self-reflection</em>: allow autonomous sgents to improve iteratively by refining past action decisions and correcting previous mistakes.</p>
</li>
<li>
<p>The second key point in the loop is how to make sure the decision maker LLM <strong>uses right tools</strong>.</p>
</li>
<li>
<p>The third key point in the loop is how to give the <strong>good feedback</strong> from the environment and how to decide to stop from the loop.</p>
</li>
</ol>
<h2 id="how-to-improve-the-reasoningplanning-ability">How to improve the reasoning/planning ability </h2>
<h3 id="task-decomposition">Task decomposition </h3>
<ol>
<li><a href="https://arxiv.org/abs/2201.11903">Chain of thought</a> has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.</li>
<li><a href="https://arxiv.org/abs/2305.10601">Tree of Thoughts</a> extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.</li>
</ol>
<h3 id="self-reflection">Self-reflection </h3>
<ol>
<li><a href="https://arxiv.org/pdf/2210.03629">ReAct</a>: integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.</li>
</ol>
<div style="text-align: center;">
  <img src="ReAct.png" alt="alt text" style="width: 80%;">
  <p><em>The figure is from <a href="https://arxiv.org/pdf/2210.03629">ReAct: Synergizing Reasoning and Acting in Language Models</a></em></p>
</div>
<ol start="2">
<li><a href="https://arxiv.org/abs/2303.11366">Reflection</a> is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps.</li>
</ol>
<div style="text-align: center;">
  <img src="image-8.png" alt="alt text" style="width: 80%;">
  <p><em>The figure is from <a href="https://arxiv.org/abs/2303.11366">Reflexion: Language Agents with Verbal Reinforcement Learning</a></em></p>
</div>
   The heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. 
<ol start="3">
<li><a href="https://arxiv.org/abs/2302.02676">Chain of Hindsight</a></li>
<li><a href="https://arxiv.org/abs/2210.14215">Algorithm Distillation</a></li>
</ol>
<h3 id="cognitive-archtecture-memories-provide-information-for-reasoningplanning">Cognitive archtecture: memories provide information for reasoning/planning </h3>
<p>How the memory plays its role for the agent's internal reasoning:</p>
<div style="text-align: center;">
  <img src="cognitive_arch_agents.png" alt="alt text" style="width: 40%;">
  <p><em>The figure is from <a href="https://arxiv.org/abs/2309.02427">Cognitive Architectures for Language Agents</a></em></p>
</div>
<p><strong>Memory for agents VS memory in human brain</strong></p>
<p>The human brain encompasses various types of memory, with its cognitive architecture broadly including the following components:</p>
<div style="text-align: center;">
  <img src="image-9.png" alt="alt text" style="width: 80%;">
  <p><em>The figure is from <a href="https://lilianweng.github.io/posts/2023-06-23-agent/">Lil's log: LLM Powered Autonomous Agents</a></em></p>
</div>
<ol>
<li><strong>Sensory memory</strong> as <strong>learning embedding representations</strong> for raw inputs, including text, image or other modalities;</li>
<li><strong>Short-term memory</strong> as <strong>in-context learning</strong>. It is short and finite, as it is restricted by the finite context window length of Transformer. The reasoning is limited by the context window.</li>
<li><strong>Long-term memory</strong> as the <strong>external vector store</strong> that the agent can attend to at query time, accessible via fast retrieval.</li>
</ol>
<p>Some works proposed we should have a cognitive architecture for an agent should align with human brain's cognitive architecture.</p>
<div style="text-align: center;">
  <img src="CoALA.png" alt="alt text" style="width: 80%;">
  <p><em>The figure is from <a href="https://arxiv.org/abs/2309.02427">Cognitive Architectures for Language Agents</a></em></p>
</div>
<h2 id="how-to-use-tools">How to use tools </h2>
<h3 id="data-stores">Data stores </h3>
<p>Data stores convert the incoming document into a set of vector database embeddings that the agent can use to extract information it needs to supplement its next action or response to the user.<br>
The key point is to store data in the form of vector embeddings. One of the most common application is the RAG based applications. For different kinds of data, the agent can have different kinds of data store.</p>
<div style="text-align: center;">
  <img src="data_stores.png" alt="alt text" style="width: 80%;">
  <p><em>The figure is from <a href="https://www.kaggle.com/whitepaper-agents">Google White Book: Agents</a></em></p>
</div>
<h3 id="external-apis">External APIs </h3>
<ol>
<li>
<p>The designer should carefully design toolsets and their documentation clearly and thoughtfully. Tool definitions and specifications should be given just as much prompt engineering attention as your overall prompts.</p>
<p>Interesting prompt engineering suggestions from <a href="https://www.anthropic.com/research/building-effective-agents">Building effective agents</a>:</p>
<blockquote>
<ol>
<li>Give the model enough tokens to "think" before it writes itself into a corner.</li>
<li>Keep the format close to what the model has seen naturally occurring in text on the internet.</li>
<li>Make sure there's no formatting "overhead" such as having to keep an accurate count of thousands of lines of code, or string-escaping any code it writes.</li>
</ol>
</blockquote>
</li>
<li>
<p>Enhancing model performance with targeted learning -- we will talk about it in the next section.</p>
</li>
</ol>
<h4 id="extensions">Extensions </h4>
<p>An extension bridges the gap between an agent and an API by:</p>
<ol>
<li>Teaching the agent how to use the API endpoint using examples.</li>
<li>Teaching the agent what arguments or parameters are needed to successfully call the API endpoint.</li>
</ol>
<div style="text-align: center;">
  <img src="extensions.png" alt="alt text" style="width: 90%;">
  <p><em>The figure is from <a href="https://www.kaggle.com/whitepaper-agents">Google White Book: Agents</a></em></p>
</div>
<h4 id="functions">Functions </h4>
<p>The agent developer might not want the LLM to manage the API execution (extensions) because of security or additional data transformation logic needs to be applied to the API response. So we want the model can be used to invoke <strong>functions</strong> in order to handle complex, client-side execution flows for the end user.</p>
<p>A typical conversation when the user ask for a ski trip suggestion:</p>
<p><img src="ski_model.png" alt="all"></p>
<p>While the above output contains the data that we need (city names), the format isn’t ideal for parsing. With Function Calling, we can teach a model to format this output in a structured style (like JSON) that’s more convenient for another system to parse.</p>
<p><img src="ski_json.png" alt="all"></p>
<p>This JSON format output can help the model to use the external API better:</p>
<p><img src="ski_agent.png" alt="all"></p>
<p>One key thing to remember about functions is that they are meant to offer the developer much more control over not only the execution of API calls, but also the entire flow of data in the application as a whole.</p>
<h3 id="workflows">Workflows </h3>
<p>Now we know how to build external data stores and how to use external APIs, the key part to use them in an Agent system is to build your own workflows used LLMs and those tools. Here are some abstractions of workflows.</p>
<p>All those figures in workflows are coming from  <a href="https://www.anthropic.com/research/building-effective-agents">Abtriouc: Building effective agents</a></p>
<ol>
<li>
<p>Prompt chaining, the gate can me programmatic checks.<br>
<img src="image-1.png" alt="alt text"></p>
</li>
<li>
<p>Routing<br>
<img src="image-2.png" alt="alt text"></p>
</li>
<li>
<p>Parallelization<br>
<img src="image-3.png" alt="alt text"></p>
</li>
<li>
<p>Orchestrator-workers<br>
<img src="image-4.png" alt="alt text"></p>
</li>
<li>
<p>Evaluator-optimizer<br>
<img src="image-5.png" alt="alt text"></p>
</li>
</ol>
<h3 id="others-model-context-protocol-mcphttpswwwanthropiccomnewsmodel-context-protocolhttpswwwanthropiccomnewsmodel-context-protocol">Others: <a href="https://www.anthropic.com/news/model-context-protocol">Model Context Protocol (MCP)</a><a href="https://www.anthropic.com/news/model-context-protocol"></a> </h3>
<p><strong>Make sure safe connection with external sources.</strong><br>
A new standard for connecting AI assistants to the systems where data lives, including content repositories, business tools, and development environments. Its aim is to help frontier models produce better, more relevant responses.</p>
<h2 id="environments">Environments </h2>
<p>This effectively simplifies the agent’s interaction with the outside world as a “text game” with textual observations and actions.</p>
<h2 id="enhancing-model-performance-with-targeted-laerning">Enhancing model performance with targeted laerning </h2>
<p>To help the model gain access to this type of specific knowledge about which tools it should select, here are some strategies:</p>
<ol>
<li>In-context learning (example: ReAct framework): provide few-shot examples at inference.</li>
<li>Retrieval-based in-context learning: dynamically populates the model prompt with the most relevant information, tools, and associated examples by retrieving them from external memory.</li>
<li>Fine-tuning based learning: training a model using a larger dataset of specific examples prior to inference.</li>
</ol>
<h2 id="case-study">Case study </h2>
<p><a href="https://agentlaboratory.github.io/">Agent laboratory: using LLM agents as research assistants</a></p>
<p><a href="https://arxiv.org/abs/2412.17767">ResearchTown: Simulator of Human Research Community</a></p>
<hr>
<h2 id="resources">Resources: </h2>
<p><em>The resources list is generated by ChatGPT.</em> 😃</p>
<ul>
<li>
<p>Research Papers</p>
<ul>
<li><a href="https://arxiv.org/abs/2201.11903">Chain of Thought Prompting</a></li>
<li><a href="https://arxiv.org/abs/2305.10601">Tree of Thoughts</a></li>
<li><a href="https://arxiv.org/pdf/2210.03629">ReAct</a></li>
<li><a href="https://arxiv.org/abs/2303.11366">Reflexion</a></li>
<li><a href="https://arxiv.org/abs/2302.02676">Chain of Hindsight</a></li>
<li><a href="https://arxiv.org/abs/2210.14215">Algorithm Distillation</a></li>
<li><a href="https://arxiv.org/abs/2309.02427">Cognitive Architectures for Language Agents</a></li>
</ul>
</li>
<li>
<p>Blog Posts and Reports</p>
<ul>
<li><a href="https://lilianweng.github.io/posts/2023-06-23-agent/">Lil's Log: LLM Powered Autonomous Agents</a></li>
<li><a href="https://www.anthropic.com/research/building-effective-agents">Building Effective Agents</a></li>
<li><a href="Agents">Agents</a></li>
<li><a href="https://www.promptingguide.ai/research/llm-agents">Prompt Engineering Guide</a></li>
</ul>
</li>
</ul>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>